# SHAP-Analysis---Feature-contribution-in-Neural-Network-Models
 
This report focuses on the exploratory data analysis and feature correlation of data generated by Abhishek Bolar at Ohio State University and geometric parameters extracted at Arizona State University. The dataset contains stamped components and their assemblies, specifically focusing on Honda T-joint. This study seeks to analyze the relationship between input features and target variables by first developing a predictive model using neural networks to estimate geometric parameters such as zone size, twist angle, and perpendicularity in a T-joint assembly. Following the model training, SHAP analysis was conducted to uncover the influence of input variables, including material thickness and width, on the target variables. A detailed breakdown of the analysis and findings is presented below.

1.	Dataset Overview
 The dataset includes various input features describing the components and assemblies. These features were analyzed to understand their distribution and impact on the target variable
Top Part:
•	Channel Width (Channel_Width_T)
•	Material (material_T: DP590 or AlNumi)
•	Thickness (Thickness_T)
•	Draw Depth (Draw_Depth_T)
•	Blank Holding Force (Blank_Holding_Force_T)
Bottom Part:
•	Channel Width (Channel_Width_B)
•	Material (material_B: DP590 or AlNumi)
•	Thickness (Thickness_B)
•	Draw Depth (Draw_Depth_B)
•	Blank Holding Force (Blank_Holding_Force_B)
Weld Patterns: Patterns defining the T-joint construction.

Distributions for all features were plotted and analyzed to understand their distribution and im-pact on the target variable     
<img width="499" alt="image" src="https://github.com/user-attachments/assets/bbf105e5-f7b3-476b-b9a9-67d2c2ff858e" />
 ![image](https://github.com/user-attachments/assets/9c952752-66cb-424f-b3f4-ce7809dab63d)
 ![image](https://github.com/user-attachments/assets/2c31d264-083e-404b-82fe-ecdb8cb58f4c)
 ![image](https://github.com/user-attachments/assets/d9d2c0c8-ea0b-4f58-9d5d-11447a40d5fb)
<img width="222" alt="image" src="https://github.com/user-attachments/assets/4333c65f-7c5c-4c8a-bc81-5d9b9bab07ba" />


2. Target Variable Analysis
The target variable, Zone Size (mm), was analyzed for its:
•	Distribution: A histogram  for distribution.
 ![image](https://github.com/user-attachments/assets/7052c001-fa2f-468f-a515-5c6280cde029)
 
•	Updated Target: A new variable, Zone Size Updated, was created by adjusting the original target with thickness values from the bottom hat and sheet.
 <img width="325" alt="image" src="https://github.com/user-attachments/assets/7b42289e-a0a6-4051-a595-fa7e6932fa69" />

•	Frequency Analysis: Samples with Zone Size Updated > 2.5 mm were filtered, and their corresponding input feature frequencies were studied.
  
 ![image](https://github.com/user-attachments/assets/4ad345d2-89a2-42c2-a661-6a541b8a2d39)


  
	 

The plots clearly demonstrate that for zone sizes greater than 2.5 mm, the frequency distributions of draw depth and blank holding force do not exhibit any discernible trends. However, distinct patterns are observed for material, channel width, and thickness, indicating their significant influence on zone size.



3. Model Development
Initial Model Training
The initial predictive model was built using a Multi-Layer Perceptron (MLP) neural network with multiple hidden layers. The following steps were undertaken:
•	Architecture: Included a series of fully connected layers with a uniform distribution of neurons.
•	Activation Function: Rectified Linear Unit (ReLU) was used for non-linear transformations.
•	Loss Function: Mean Squared Error (MSE) was used to evaluate model performance.
•	Train-Test Split: The dataset was split into 80% training, 10% Validation and 10% testing subsets for robust evaluation.
Initial Results:
•	Training MSE was considerably lower than the test MSE, with values around 0.004 and 0.20, respectively.
•	This discrepancy indicated overfitting, where the model captured noise and patterns specific to the training data, reducing its generalization ability on unseen data.
Addressing Overfitting
To combat overfitting and improve model performance, the following strategies were implemented:
1.	Regularization:
o	ElasticNet Regularization: A combination of L1 and L2 penalties was applied to control model complexity and reduce overfitting.
o	Dropout Layers: Dropout was introduced to randomly deactivate neurons during training, preventing reliance on specific pathways and encouraging a more robust model.
2.	Hyperparameter Tuning:
o	The number of layers and neurons was carefully adjusted.
o	The regularization strength (alpha) was fine-tuned to balance underfitting and overfitting.
o	Learning rate and batch size were optimized for stable training.
3.	Early Stopping:
o	Early stopping was employed to halt training once validation loss ceased to improve, ensuring the model did not overfit to the training data.
4.	Feature Scaling:
o	StandardScaler was used to normalize input features, ensuring all variables contributed equally to the learning process.
Improved Results
After implementing these strategies:
•	Test MSE improved to 0.14, indicating better generalization to unseen data.
•	Training Loss vs. Test Loss: The gap between training and test loss significantly narrowed. This indicated that the model was no longer overfitting and had learned meaningful patterns from the data.
•	Performance Insights:
o	The model achieved a balance between bias and variance, as evidenced by consistent performance on both training and test sets.
o	Visualizations of the training loss over epochs showed smoother convergence and reduced oscillations after applying regularization and early stopping.
Key Observations
1.	Effect of Depth and Width: Increasing the depth of the network with carefully tuned layer sizes improved the model’s ability to capture complex relationships.
2.	Regularization’s Role: Regularization prevented the model from fitting noise, leading to a better representation of underlying data trends.
3.	Early Stopping Efficiency: By avoiding unnecessary additional epochs, early stopping ensured optimal weights without overfitting.
The final model, with a test MSE of 0.14 and a training MSE of 0.12, demonstrated robust predictive performance while addressing overfitting concerns effectively.

4. SHAP Analysis
What is SHAP?
SHAP (SHapley Additive exPlanations) is a framework for interpreting machine learning models. It assigns each feature an importance value for a specific prediction, based on game theory concepts. SHAP:
•	Explains Predictions: Shows how individual features contribute to a model's output.
•	Feature Importance: Ranks features based on their overall impact.
•	Visualization: Provides summary and force plots to interpret the results.
Key Components of SHAP
1.	Global Explanations:
o	SHAP identifies the overall importance of each feature across the entire dataset.
o	This helps to understand which features have the most significant impact on model predictions.
2.	Local Explanations:
o	For individual predictions, SHAP explains how much each feature contributes to the specific output.
o	Positive SHAP values indicate features pushing the prediction higher, while negative values indicate features pulling it lower.
3.	Additive Feature Attribution:
o	SHAP ensures the sum of all feature attributions equals the difference between the model's prediction and a baseline value (e.g., the average prediction).

SHAP Insights in the Study
In this study, SHAP analysis revealed the following:




















1.	Feature Importance:
o	The features are ranked based on their importance, with the most impactful feature at the top. The x-axis represents the SHAP value, which indicates the direction and magnitude of a feature's impact on the model output.
o	Top Features:
	Thickness_B (Thickness of the bottom part) has the most significant impact on the model predictions. Its SHAP values show both positive and negative contributions depending on the feature value.
	Channel_Width_B (Channel width of the bottom part) is the second most impactful feature, showing clear trends with SHAP values.
2.	Directional Impact of Features:
o	Thickness_B:
	High values (red dots) tend to have a negative SHAP value, reducing the model output (zone size).
	Low values (blue dots) have a positive SHAP value, increasing the model output (zone size).
	Conclusion: Thicker bottom sheets result in smaller zone sizes, while thinner sheets increase the zone size.
o	Channel_Width_B:
	High values (red dots) generally contribute to positive SHAP values, increasing the zone size.
	Low values (blue dots) contribute to negative SHAP values, decreasing the zone size.
	Conclusion: Wider channels increases zone sizes, whereas narrower channels decrease them.
3.	Material Influence:
o	Material 100:DP590 200:AlNumi_B:
	The plot suggests that DP590 (coded as 100) tends to reduce the zone size, as indicated by the clustering of blue dots on the left.
	AlNumi (coded as 200) contributes positively to the zone size.
	Conclusion: The material type strongly influences the model predictions, with DP590 reducing the zone size and AlNumi increasing it.
4.	Negligible Features:
o	Features such as Draw_Depth_T, Blank_Holding_Force_T, Draw_Depth_B, and Blank_Holding_Force_B have minimal SHAP value dispersion and clustering near zero. This indicates they have little to no impact on the predictions.
5.	Other Observations:
o	Features like Weld_Pattern, Thickness_T, and Channel_Width_T contribute minimally compared to their bottom counterparts.

Conclusion:
•	The thickness of the bottom sheet (Thickness_B) and the channel width of the bottom sheet (Channel_Width_B) are the most critical factors influencing the zone size.
•	The material of the bottom sheet (DP590 vs. AlNumi) also plays a significant role.
•	The draw depth and blank holding force for both top and bottom parts show negligible impact on the model predictions.

 

SHAP ANALYSIS OF TWIST ANGLE



	Twist angle analysis was done on the top hat left and right flange. Image to the left indicates for bottom





 



The SHAP summary plot illustrates the impact of input features on the prediction of the target variable, Twist Angle. Below is a detailed analysis:

Feature Importance
1.	Top Influencing Features:
o	Thickness_T (Thickness of the top part) has the most substantial impact on the model's prediction for twist angle. Its SHAP values show both positive and negative contributions depending on the feature values.
o	Draw_Depth_T is the second most influential feature, showing a moderate effect on the model’s predictions.
o	Material_T, less significantly but still provide meaningful impacts.
2.	Negligible Features:
o	Among the features , Channel_Width_T, and Blank_Holding_Force_T exhibits the least variation in SHAP values, indicating a relatively small influence on the predicted twist angle.

Directional Impact of Features
1.	Thickness_T:
o	High Thickness (red dots):
	Negative SHAP values, meaning thicker top parts contribute to lower predicted twist angles.
o	Low Thickness (blue dots):
	Positive SHAP values, meaning thinner top parts lead to higher predicted twist angles.
o	Conclusion: Thickness_T is negatively correlated with the twist angle.
2.	Draw_Depth_T:
o	High Draw Depth (red dots):
	Tends to increase the twist angle (Positive SHAP values).
o	Low Draw Depth (blue dots):
	Contributes negatively to the twist angle.
o	Conclusion: Draw_Depth_T is positively correlated with the twist angle.
3.	Material_T:
o	Material DP590 (blue dots):
	Typically contributes negatively to the twist angle (negative SHAP values).
o	Material AlNumi (red dots):
	Associated with positive SHAP values, increasing the twist angle.
o	Conclusion: Material type significantly influences the twist angle, with DP590 reducing it and AlNumi increasing it.


Conclusion
The SHAP analysis highlights Thickness_T, Draw_Depth_T, and Material_T as the most critical features in predicting the twist angle in the T-joint assembly. The insights from this analysis can guide design optimization and parameter adjustments to control twist angle effectively.
 
![image](https://github.com/user-attachments/assets/81c5c3dd-a118-4b8b-9ea2-f1e78bd232a8)
